---
title: "Homework 3"
author: "Qi Lin"
date: "`r format(Sys.time(), '%B %d, %Y')`"
output: github_document
---

```{r, message=FALSE}
library('splines')        ## for 'bs'
library('dplyr')          ## for 'select', 'filter', and others
library('magrittr')       ## for '%<>%' operator
library('glmnet')         ## for 'glmnet'
```


```{r}
## load prostate data
prostate <- 
  read.table(url(
    'https://web.stanford.edu/~hastie/ElemStatLearn/datasets/prostate.data'))
```

- Use the cor function to reproduce the correlations listed in HTF Table 3.1, page 50.

```{r}
Cl <- round(cor(prostate),3)

#as.matrix(Cl)

Cl[upper.tri(Cl, diag = T)] <- ''

Cl.df <- as.data.frame(Cl)

Cl.df = Cl.df[-c(1,9,10),]%>% select(-c(pgg45,lpsa,train))

Cl.df
```

- Treat lcavol as the outcome, and use all other variables in the data set as predictors.
- With the training subset of the prostate data, train a least-squares regression model with all predictors using the lm function.

```{r}
## split prostate into testing and training subsets
prostate_train <- prostate %>%
  filter(train == TRUE) %>% 
  select(-train)

prostate_test <- prostate %>%
  filter(train == FALSE) %>% 
  select(-train)


## predict lcavol consider all other predictors
## lm fits using L2 loss
fit <- lm(lcavol ~ ., data=prostate_train)
# summary(fit)
```

- Use the testing subset to compute the test error (average squared-error loss) using the fitted least-squares regression model.

```{r}
pred = predict(fit, prostate_test)

Test_Error = mean((prostate_test$lcavol-pred)^2)

cat('The test error is:',Test_Error)
```

- Train a ridge regression model using the glmnet function, and tune the value of lambda (i.e., use guess and check to find the value of lambda that approximately minimizes the test error).

```{r}
form  <- lcavol ~  lweight + age + lbph + lcp + pgg45 + lpsa + svi + gleason
x_inp <- model.matrix(form, data=prostate_train)
y_out <- prostate_train$lcavol
fit <- glmnet(x=x_inp, y=y_out, lambda=seq(0.5, 0, -0.05), alpha = 0) #0 = ridge
print(fit$beta)
```

- Create a figure that shows the training and test error associated with ridge regression as a function of lambda

```{r}
## functions to compute testing/training error w/lm
L2_loss <- function(y, yhat)
  (y-yhat)^2

## functions to compute testing/training error with glmnet
error <- function(dat, fit, lam, form, loss=L2_loss) {
  x_inp <- model.matrix(form, data=dat)
  y_out <- dat$lcavol
  y_hat <- predict(fit, newx=x_inp, s=lam)  ## see predict.elnet
  mean(loss(y_out, y_hat))
}

## compute training and testing errors as function of lambda
err_train_1 <- sapply(fit$lambda, function(lam) 
  error(prostate_train, fit, lam, form))
err_test_1 <- sapply(fit$lambda, function(lam) 
  error(prostate_test, fit, lam, form))

## plot test/train error
plot(x=range(fit$lambda),
     y=range(c(err_train_1, err_test_1)),
     xlim=rev(range(fit$lambda)),
     type='n',
     xlab=expression(lambda),
     ylab='train/test error')
points(fit$lambda, err_train_1, pch=19, type='b', col='darkblue')
points(fit$lambda, err_test_1, pch=19, type='b', col='darkred')
legend('topright', c('train','test'), lty=1, pch=19,
       col=c('darkblue','darkred'), bty='n')

colnames(fit$beta) <- paste('lam =', fit$lambda)
print(fit$beta %>% as.matrix)
```

- Create a path diagram of the ridge regression analysis, similar to HTF Figure 3.8

```{r}
## plot path diagram
plot(x=range(fit$lambda),
     y=range(as.matrix(fit$beta)),
     type='n',
     xlab=expression(lambda),
     ylab='Coefficients')
for(i in 1:nrow(fit$beta)) {
  points(x=fit$lambda, y=fit$beta[i,], pch=19, col='red')
  lines(x=fit$lambda, y=fit$beta[i,], col='red')
}
text(x=0, y=fit$beta[,ncol(fit$beta)], 
     labels=rownames(fit$beta),
     xpd=NA, pos=4, srt=45)
abline(h=0, lty=3, lwd=2)
```

